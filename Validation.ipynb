{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation.ipynb\n",
    "Reproduce XML schema validation and enumerated field results from \"Obstacles to the Use of Study Metadata in ClinicalTrials.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from io import StringIO\n",
    "import sys, re, os, pdb, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_data_dir = '/Users/lauramiron/Large_files/CTData/'\n",
    "xml_dir = root_data_dir+'AllPublicXML/'\n",
    "results_dir = 'results/'\n",
    "val_results_csv = results_dir+'xml_val_results.csv'\n",
    "\n",
    "xml_files = [os.path.join(root, f) for root, dirs, files in os.walk(xml_dir) for f in files if f.split('.')[1]=='xml']\n",
    "NUM_RECORDS = len(xml_files)\n",
    "print_progress=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xml(filename_xml):\n",
    "    with open(filename_xml, 'r') as xml_file:\n",
    "        xml_to_check = xml_file.read()\n",
    "    try:\n",
    "        doc = etree.parse(StringIO(xml_to_check))\n",
    "        return doc\n",
    "    except IOError:\n",
    "        return None\n",
    "    except etree.XMLSyntaxError as err:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Validation\n",
    "Check whether XML records validate against the provided XML schema (public.xsd).\n",
    "\n",
    "Note: For simplicity, paper states that all records correctly validate against schema. In fact, two records out of 302,091 fail to validate.  NCT02321462.xml  and NCT02493517.xml both contain values 'non-inferiority' instead of 'Non-Inferiority' for field 'non_inferiority_type', which is an optional clinical results element.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_rmenc(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        xml_string = f.read()\n",
    "        RE_XML_ENCODING = re.match(r'<\\?xml[^>]+\\s+(encoding\\s*=\\s*[\"\\'][^\"\\']*[\"\\'])\\s*\\?>|',xml_string).group(1)\n",
    "        cleaned = re.sub(RE_XML_ENCODING,\"\", xml_string)\n",
    "        return cleaned\n",
    "    \n",
    "def load_schema(filename_xsd):\n",
    "    schema_to_check = open_rmenc(filename_xsd)\n",
    "    xmlschema_doc = etree.parse(StringIO(schema_to_check))\n",
    "    xmlschema = etree.XMLSchema(xmlschema_doc)\n",
    "    return xmlschema\n",
    "\n",
    "def _is_valid_xml(xml_doc, xmlschema):\n",
    "    try:\n",
    "        xmlschema.assertValid(xml_doc)\n",
    "        return True\n",
    "    except etree.DocumentInvalid as err:\n",
    "        print(err)\n",
    "        return False\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_xsd = root_data_dir+'public.xsd'\n",
    "\n",
    "valid = 0\n",
    "invalid = 0\n",
    "malformed = 0\n",
    "\n",
    "xmlschema = load_schema(filename_xsd)\n",
    "print(\"Running validation on \",len(xml_files),\" xml files...\")\n",
    "for i, xmlf in enumerate(xml_files):\n",
    "    if (print_progress==True) and (i % 1000 == 0): print(i,'/',len(xml_files))\n",
    "    with open(val_results_csv,'a+') as of:\n",
    "        xml_doc = load_xml(xmlf)\n",
    "        if not xml_doc:\n",
    "            of.write(xmlf.split('/')[-1]+',Malformed XML\\n')\n",
    "            malformed += 1\n",
    "        else:\n",
    "            validates = _is_valid_xml(xml_doc,xmlschema)\n",
    "            of.write(xmlf.split('/')[-1]+','+str(validates)+'\\n')\n",
    "            if validates: valid += 1\n",
    "            else: invalid += 1\n",
    "print('Total: ',len(xml_files),', Valid: ',valid,', Invalid: ',invalid,', Malformed: ',malformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerated Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment lines 26-32 to run to re-generate pickled dataframes of values for enumerated fields\n",
    "# Our dataframes are already located in CTData\n",
    "enumerated_data_dir = 'scraped/'\n",
    "\n",
    "def xml_to_dataframe(col,recursive=False,stop=None):\n",
    "    data = []\n",
    "    df = pd.DataFrame()\n",
    "    print(f'Scraping xml to make dataframe for col {col}...')\n",
    "    for count, xmlf in enumerate(xml_files,0):\n",
    "        if (stop is not None):\n",
    "            if count>stop: break\n",
    "        try:\n",
    "            if (print_progress==True) and (count % 10000 == 0): print(f'{count}/{len(xml_files)}')    \n",
    "            xml_doc = load_xml(xmlf)\n",
    "            findstr = './/'+col if recursive else col\n",
    "            elems = xml_doc.findall(findstr)\n",
    "            for el in elems:\n",
    "                data.append((xmlf.split('/')[-1],el.text))\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "    df = pd.DataFrame(data,columns=['filename',col])\n",
    "    df.to_pickle(enumerated_data_dir+col+'.p')\n",
    "    return df\n",
    "\n",
    "# scrape xml files, make pandas dataframe for each field that should be an enum\n",
    "# df1 = xml_to_dataframe('primary_purpose',recursive=True)\n",
    "# df2 = xml_to_dataframe('intervention_model',recursive=True)\n",
    "# df3 = xml_to_dataframe('masking',recursive=True)\n",
    "# df4 = xml_to_dataframe('allocation',recursive=True)\n",
    "# df5 = xml_to_dataframe('arm_group_type',recursive=True)\n",
    "# df6 = xml_to_dataframe('observational_model',recursive=True)\n",
    "# df7 = xml_to_dataframe('time_perspective', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check string xml fields against list of valid values on clinicaltrials.gov\n",
    "int_model_choices = ['Single Group Assignment', 'Parallel Assignment', 'Crossover Assignment', 'Factorial Assignment', 'Sequential Assignment']\n",
    "mask_choices = ['Participant', 'Care Provider', 'Investigator', 'Outcomes Assessor', 'No Masking']\n",
    "primary_purpose_choices = ['Treatment', 'Prevention', 'Diagnostic', 'Supportive Care', 'Screening', 'Health Services Research', 'Basic Science', 'Device Feasibility', 'Other','Educational/Counseling/Training']\n",
    "alloc_choices = ['N/A', 'Randomized', 'Non-Randomized']\n",
    "arm_group_type_choices = ['Experimental', 'Active Comparator', 'Placebo Comparator', 'Sham Comparator', 'No Intervention', 'Other']\n",
    "obs_model_choices = ['Cohort', 'Case-Control', 'Case-Only', 'Case-Crossover', 'Ecologic or Community', 'Family-Based', 'Other']\n",
    "time_perspective_choices = ['Prospective','Cross-Sectional','Retrospective','Other']\n",
    "\n",
    "\n",
    "enumerated_data_dir = 'scraped/'\n",
    "\n",
    "# Interventional Study Model\n",
    "print('INTERVENTIONAL STUDY MODEL')\n",
    "df = pd.read_pickle(enumerated_data_dir+'intervention_model.p')\n",
    "print(df['intervention_model'].value_counts())\n",
    "df_rogue = df[~df['intervention_model'].isin(int_model_choices)]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Masking\n",
    "print('MASKING')\n",
    "mask_pattern = r'(None \\(Open Label\\))|(Single \\((Participant(, )?|Care Provider(, )?|Investigator(, )?|Outcomes Assessor(, )?){1}\\))|(Double \\((Participant(, )?|Care Provider(, )?|Investigator(, )?|Outcomes Assessor(, )?){2}\\))|(Triple \\((Participant(, )?|Care Provider(, )?|Investigator(, )?|Outcomes Assessor(, )?){3}\\))|(Quadruple \\((Participant(, )?|Care Provider(, )?|Investigator(, )?|Outcomes Assessor(, )?){4}\\))'\n",
    "simple_mask_pattern = r'(Single|Double|Triple|Quadruple)'\n",
    "df = pd.read_pickle(enumerated_data_dir+'masking.p')\n",
    "print(df['masking'].value_counts())\n",
    "df_rogue = df[~((df.masking.str.match(mask_pattern)) | (df.masking.str.match(simple_mask_pattern)))]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Primary Purpose\n",
    "print('PRIMARY PURPOSE')\n",
    "df = pd.read_pickle(enumerated_data_dir+'primary_purpose.p')\n",
    "print(df['primary_purpose'].value_counts())\n",
    "df_rogue = df[~df['primary_purpose'].isin(primary_purpose_choices)]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Allocation\n",
    "print('ALLOCATION')\n",
    "df = pd.read_pickle(enumerated_data_dir+'allocation.p')\n",
    "print(df['allocation'].value_counts())\n",
    "df_rogue = df[~df['allocation'].isin(alloc_choices)]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Arm Type\n",
    "print('ARM TYPE')\n",
    "df = pd.read_pickle(enumerated_data_dir+'arm_group_type.p')\n",
    "print(df['arm_group_type'].value_counts())\n",
    "df_rogue = df[~df['arm_group_type'].isin(arm_group_type_choices)]\n",
    "# may be more than one rogue arm_group_type per record, count num records with rogue values\n",
    "# for consistency with rest of data table\n",
    "num_rogue = df_rogue['filename'].nunique() \n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Observational Model\n",
    "print('OBSERVATIONAL MODEL')\n",
    "df = pd.read_pickle(enumerated_data_dir+'observational_model.p')\n",
    "print(df['observational_model'].value_counts())\n",
    "df_rogue = df[~df['observational_model'].isin(obs_model_choices)]\n",
    "# may be more than one rogue arm_group_type per record, count num records with rogue values\n",
    "# for consistency with rest of data table\n",
    "num_rogue = df_rogue['filename'].nunique() \n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Time Perspective\n",
    "def _valid_time_perspective(row):\n",
    "    value = row['time_perspective']\n",
    "    for term in value.split(','):\n",
    "        if (term.strip()!= '') and term.strip() not in time_perspective_choices:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print('TIME PERSPECTIVE')\n",
    "df = pd.read_pickle(enumerated_data_dir+'time_perspective.p')\n",
    "print(df['time_perspective'].value_counts())\n",
    "df_rogue = df[~df.apply(_valid_time_perspective, axis=1)]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
