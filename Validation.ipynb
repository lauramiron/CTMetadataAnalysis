{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation.ipynb\n",
    "Reproduce XML schema validation and enumerated field results from \"Obstacles to the Use of Study Metadata in ClinicalTrials.gov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from io import StringIO\n",
    "import sys, re, os, pdb, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root_data_dir = '/Users/lauramiron/Large_files/CTData/'\n",
    "xml_dir = root_data_dir+'AllPublicXML/'\n",
    "results_dir = 'results/'\n",
    "val_results_csv = results_dir+'xml_val_results.csv'\n",
    "\n",
    "xml_files = [os.path.join(root, f) for root, dirs, files in os.walk(xml_dir) for f in files if f.split('.')[1]=='xml']\n",
    "NUM_RECORDS = len(xml_files)\n",
    "print_progress=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xml(filename_xml):\n",
    "    with open(filename_xml, 'r') as xml_file:\n",
    "        xml_to_check = xml_file.read()\n",
    "    try:\n",
    "        doc = etree.parse(StringIO(xml_to_check))\n",
    "        return doc\n",
    "    except IOError:\n",
    "        return None\n",
    "    except etree.XMLSyntaxError as err:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Validation\n",
    "Check whether XML records validate against the provided XML schema (public.xsd).\n",
    "\n",
    "Note: For simplicity, paper states that all records correctly validate against schema. In fact, two records out of 302,091 fail to validate.  NCT02321462.xml  and NCT02493517.xml both contain values 'non-inferiority' instead of 'Non-Inferiority' for field 'non_inferiority_type', which is an optional clinical results element.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_rmenc(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        xml_string = f.read()\n",
    "        RE_XML_ENCODING = re.match(r'<\\?xml[^>]+\\s+(encoding\\s*=\\s*[\"\\'][^\"\\']*[\"\\'])\\s*\\?>|',xml_string).group(1)\n",
    "        cleaned = re.sub(RE_XML_ENCODING,\"\", xml_string)\n",
    "        return cleaned\n",
    "    \n",
    "def load_schema(filename_xsd):\n",
    "    schema_to_check = open_rmenc(filename_xsd)\n",
    "    xmlschema_doc = etree.parse(StringIO(schema_to_check))\n",
    "    xmlschema = etree.XMLSchema(xmlschema_doc)\n",
    "    return xmlschema\n",
    "\n",
    "def _is_valid_xml(xml_doc, xmlschema):\n",
    "    try:\n",
    "        xmlschema.assertValid(xml_doc)\n",
    "        return True\n",
    "    except etree.DocumentInvalid as err:\n",
    "        print(err)\n",
    "        return False\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_xsd = root_data_dir+'public.xsd'\n",
    "\n",
    "valid = 0\n",
    "invalid = 0\n",
    "malformed = 0\n",
    "\n",
    "xmlschema = load_schema(filename_xsd)\n",
    "print(\"Running validation on \",len(xml_files),\" xml files...\")\n",
    "for i, xmlf in enumerate(xml_files):\n",
    "    if (print_progress==True) and (i % 1000 == 0): print(i,'/',len(xml_files))\n",
    "    with open(val_results_csv,'a+') as of:\n",
    "        xml_doc = load_xml(xmlf)\n",
    "        if not xml_doc:\n",
    "            of.write(xmlf.split('/')[-1]+',Malformed XML\\n')\n",
    "            malformed += 1\n",
    "        else:\n",
    "            validates = _is_valid_xml(xml_doc,xmlschema)\n",
    "            of.write(xmlf.split('/')[-1]+','+str(validates)+'\\n')\n",
    "            if validates: valid += 1\n",
    "            else: invalid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  302091 , Valid:  302089 , Invalid:  2 , Malformed:  0\n"
     ]
    }
   ],
   "source": [
    "print('Total: ',len(xml_files),', Valid: ',valid,', Invalid: ',invalid,', Malformed: ',malformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerated Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment lines 26-32 to run to re-generate pickled dataframes of values for enumerated fields\n",
    "# Our dataframes are already located in CTData\n",
    "enumerated_data_dir = 'cache/'\n",
    "\n",
    "def xml_to_dataframe(col,recursive=False,stop=None):\n",
    "    data = []\n",
    "    df = pd.DataFrame()\n",
    "    print(f'Scraping xml to make dataframe for col {col}...')\n",
    "    for count, xmlf in enumerate(xml_files,0):\n",
    "        if (stop is not None):\n",
    "            if count>stop: break\n",
    "        try:\n",
    "            if (print_progress==True) and (count % 10000 == 0): print(f'{count}/{len(xml_files)}')    \n",
    "            xml_doc = load_xml(xmlf)\n",
    "            findstr = './/'+col if recursive else col\n",
    "            elems = xml_doc.findall(findstr)\n",
    "            for el in elems:\n",
    "                data.append((xmlf.split('/')[-1],el.text))\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "    df = pd.DataFrame(data,columns=['filename',col])\n",
    "    df.to_pickle(enumerated_data_dir+col+'.p')\n",
    "    return df\n",
    "\n",
    "# scrape xml files, make pandas dataframe for each field that should be an enum\n",
    "df1 = xml_to_dataframe('primary_purpose',recursive=True)\n",
    "df2 = xml_to_dataframe('intervention_model',recursive=True)\n",
    "df3 = xml_to_dataframe('masking',recursive=True)\n",
    "df4 = xml_to_dataframe('allocation',recursive=True)\n",
    "df5 = xml_to_dataframe('arm_group_type',recursive=True)\n",
    "df6 = xml_to_dataframe('observational_model',recursive=True)\n",
    "df7 = xml_to_dataframe('time_perspective', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVENTIONAL STUDY MODEL\n",
      "Parallel Assignment        136069\n",
      "Single Group Assignment     69339\n",
      "Crossover Assignment        21161\n",
      "Factorial Assignment         3737\n",
      "Sequential Assignment        2134\n",
      "Name: intervention_model, dtype: int64\n",
      "Num records with rogue values: 0, 0.00%\n",
      "\n",
      "MASKING\n",
      "None (Open Label)                                                          131633\n",
      "Quadruple (Participant, Care Provider, Investigator, Outcomes Assessor)     22869\n",
      "Double (Participant, Investigator)                                          17390\n",
      "Single (Outcomes Assessor)                                                  13088\n",
      "Single (Participant)                                                        11433\n",
      "Triple (Participant, Care Provider, Investigator)                            7192\n",
      "Triple (Participant, Investigator, Outcomes Assessor)                        6489\n",
      "Double                                                                       6200\n",
      "Double (Participant, Outcomes Assessor)                                      5057\n",
      "Single (Investigator)                                                        3971\n",
      "Double (Investigator, Outcomes Assessor)                                     2166\n",
      "Double (Participant, Care Provider)                                          1809\n",
      "Triple (Participant, Care Provider, Outcomes Assessor)                       1626\n",
      "Single                                                                       1285\n",
      "Single (Care Provider)                                                        683\n",
      "Triple (Care Provider, Investigator, Outcomes Assessor)                       393\n",
      "Double (Care Provider, Outcomes Assessor)                                     324\n",
      "Double (Care Provider, Investigator)                                          242\n",
      "Name: masking, dtype: int64\n",
      "Num records with rogue values: 0, 0.00%\n",
      "\n",
      "PRIMARY PURPOSE\n",
      "Treatment                          159033\n",
      "Prevention                          25285\n",
      "Basic Science                       11128\n",
      "Diagnostic                          10481\n",
      "Supportive Care                      9706\n",
      "Other                                7816\n",
      "Health Services Research             5159\n",
      "Screening                            2126\n",
      "Device Feasibility                    489\n",
      "Educational/Counseling/Training       196\n",
      "Name: primary_purpose, dtype: int64\n",
      "Num records with rogue values: 0, 0.00%\n",
      "\n",
      "ALLOCATION\n",
      "Randomized        155479\n",
      "Non-Randomized     27305\n",
      "Random Sample         78\n",
      "Name: allocation, dtype: int64\n",
      "Num records with rogue values: 78, 0.03%\n",
      "\n",
      "ARM TYPE\n",
      "Experimental            252719\n",
      "Active Comparator       107509\n",
      "Placebo Comparator       46567\n",
      "No Intervention          23737\n",
      "Other                    21892\n",
      "Sham Comparator           5115\n",
      "Case                        30\n",
      "Control                     17\n",
      "Treatment Comparison         2\n",
      "Name: arm_group_type, dtype: int64\n",
      "Num records with rogue values: 21, 0.01%\n",
      "\n",
      "OBSERVATIONAL MODEL\n",
      "Cohort                                 31710\n",
      "Case-Only                               8879\n",
      "Case Control                            4514\n",
      "Case-Control                            4147\n",
      "Other                                   3423\n",
      "Ecologic or Community                    704\n",
      "Case-Crossover                           572\n",
      "Family-Based                             377\n",
      "Defined Population                       373\n",
      "Defined Population, Natural History      296\n",
      "Natural History                           92\n",
      "Case Control, Natural History             68\n",
      "Name: observational_model, dtype: int64\n",
      "Num records with rogue values: 5343, 1.77%\n",
      "\n",
      "TIME PERSPECTIVE\n",
      "Prospective                                   41981\n",
      "Retrospective                                  7245\n",
      "Cross-Sectional                                6606\n",
      "Other                                          1531\n",
      "Longitudinal, Prospective                       374\n",
      "Cross-Sectional, Prospective                    270\n",
      "Longitudinal, Retrospective                      84\n",
      "Longitudinal, Retrospective/Prospective          81\n",
      "Cross-Sectional, Retrospective                   80\n",
      "Cross-Sectional, Retrospective/Prospective       71\n",
      "Longitudinal                                     11\n",
      "Retrospective/Prospective                         1\n",
      "Name: time_perspective, dtype: int64\n",
      "Num records with rogue values: 622, 0.21%\n"
     ]
    }
   ],
   "source": [
    "# Check string xml fields against list of valid values on clinicaltrials.gov\n",
    "int_model_choices = ['Single Group Assignment', 'Parallel Assignment', 'Crossover Assignment', 'Factorial Assignment', 'Sequential Assignment']\n",
    "mask_choices = ['Participant', 'Care Provider', 'Investigator', 'Outcomes Assessor', 'No Masking']\n",
    "primary_purpose_choices = ['Treatment', 'Prevention', 'Diagnostic', 'Supportive Care', 'Screening', 'Health Services Research', 'Basic Science', 'Device Feasibility', 'Other','Educational/Counseling/Training']\n",
    "alloc_choices = ['N/A', 'Randomized', 'Non-Randomized']\n",
    "arm_group_type_choices = ['Experimental', 'Active Comparator', 'Placebo Comparator', 'Sham Comparator', 'No Intervention', 'Other']\n",
    "obs_model_choices = ['Cohort', 'Case-Control', 'Case-Only', 'Case-Crossover', 'Ecologic or Community', 'Family-Based', 'Other']\n",
    "time_perspective_choices = ['Prospective','Cross-Sectional','Retrospective','Other']\n",
    "\n",
    "\n",
    "enumerated_data_dir = 'cache/'\n",
    "\n",
    "# Interventional Study Model\n",
    "print('INTERVENTIONAL STUDY MODEL')\n",
    "df = pd.read_pickle(enumerated_data_dir+'intervention_model.p')\n",
    "print(df['intervention_model'].value_counts())\n",
    "df_rogue = df[~df['intervention_model'].isin(int_model_choices)]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Masking\n",
    "print('\\nMASKING')\n",
    "mask_pattern = r'(None \\(Open Label\\))|(Single \\((Participant(, )?|Care Provider(, )?|Investigator(, )?|Outcomes Assessor(, )?){1}\\))|(Double \\((Participant(, )?|Care Provider(, )?|Investigator(, )?|Outcomes Assessor(, )?){2}\\))|(Triple \\((Participant(, )?|Care Provider(, )?|Investigator(, )?|Outcomes Assessor(, )?){3}\\))|(Quadruple \\((Participant(, )?|Care Provider(, )?|Investigator(, )?|Outcomes Assessor(, )?){4}\\))'\n",
    "simple_mask_pattern = r'(Single|Double|Triple|Quadruple)'\n",
    "df = pd.read_pickle(enumerated_data_dir+'masking.p')\n",
    "print(df['masking'].value_counts())\n",
    "df_rogue = df[~((df.masking.str.match(mask_pattern)) | (df.masking.str.match(simple_mask_pattern)))]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Primary Purpose\n",
    "print('\\nPRIMARY PURPOSE')\n",
    "df = pd.read_pickle(enumerated_data_dir+'primary_purpose.p')\n",
    "print(df['primary_purpose'].value_counts())\n",
    "df_rogue = df[~df['primary_purpose'].isin(primary_purpose_choices)]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Allocation\n",
    "print('\\nALLOCATION')\n",
    "df = pd.read_pickle(enumerated_data_dir+'allocation.p')\n",
    "print(df['allocation'].value_counts())\n",
    "df_rogue = df[~df['allocation'].isin(alloc_choices)]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Arm Type\n",
    "print('\\nARM TYPE')\n",
    "df = pd.read_pickle(enumerated_data_dir+'arm_group_type.p')\n",
    "print(df['arm_group_type'].value_counts())\n",
    "df_rogue = df[~df['arm_group_type'].isin(arm_group_type_choices)]\n",
    "# may be more than one rogue arm_group_type per record, count num records with rogue values\n",
    "# for consistency with rest of data table\n",
    "num_rogue = df_rogue['filename'].nunique() \n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Observational Model\n",
    "print('\\nOBSERVATIONAL MODEL')\n",
    "df = pd.read_pickle(enumerated_data_dir+'observational_model.p')\n",
    "print(df['observational_model'].value_counts())\n",
    "df_rogue = df[~df['observational_model'].isin(obs_model_choices)]\n",
    "# may be more than one rogue arm_group_type per record, count num records with rogue values\n",
    "# for consistency with rest of data table\n",
    "num_rogue = df_rogue['filename'].nunique() \n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')\n",
    "\n",
    "# Time Perspective\n",
    "def _valid_time_perspective(row):\n",
    "    value = row['time_perspective']\n",
    "    for term in value.split(','):\n",
    "        if (term.strip()!= '') and term.strip() not in time_perspective_choices:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print('\\nTIME PERSPECTIVE')\n",
    "df = pd.read_pickle(enumerated_data_dir+'time_perspective.p')\n",
    "print(df['time_perspective'].value_counts())\n",
    "df_rogue = df[~df.apply(_valid_time_perspective, axis=1)]\n",
    "num_rogue = len(df_rogue)\n",
    "print(f'Num records with rogue values: {num_rogue}, {float(num_rogue)/NUM_RECORDS:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
